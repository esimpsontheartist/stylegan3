{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StyleGAN3 and Music Lucid AI Video Maker.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esimpsontheartist/stylegan3/blob/main/StyleGAN3_and_Music_Lucid_AI_Video_Maker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHzltei9Ue7I"
      },
      "source": [
        "#StyleGAN3 and Music Video Maker\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Op3tRUgOXVRU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVF2P1OlT92b"
      },
      "source": [
        "#Lucid Stylegan3 models evaluation\n",
        "\n",
        "This basic colab notebook is to try out the **[lucid stylegan3 datasets and models](https://github.com/edstoica/lucid_stylegan3_datasets_models)** collection.\n",
        "\n",
        "This notebook is derived from [here](https://colab.research.google.com/drive/1BXNHZBai-pXtP-ncliouXo_kUiG1Pq7M?usp=sharing#scrollTo=WVF2P1OlT92b). \n",
        "\n",
        "<!--\n",
        "**[UPD 18.10.2021]** Added ThisSneakersDoesn'tExist model by [@stan_vossen](https://twitter.com/stan_vossen)  +  seems like [@l4rz](https://twitter.com/l4rz) killed the model for cosplay\n",
        "\n",
        "[UPD 17.10.2021] Added Music Video Generation (originally inspired by [this tweet](https://twitter.com/hexorcismos/status/1449032666574213125?s=20))\n",
        "\n",
        "[UPD 14.10.2021] Added Cosplay Faces trained by [@l4rz](https://twitter.com/l4rz)-->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d99HsTjTQRzg",
        "cellView": "form"
      },
      "source": [
        "#@title Install System\n",
        "#@markdown play only once (ignore that memory warning)\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "%cd stylegan3\n",
        "!wget -O mini.sh https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.2-Linux-x86_64.sh\n",
        "!chmod +x mini.sh\n",
        "!bash ./mini.sh -b -f -p /usr/local\n",
        "!conda install -q -y --prefix /usr/local jupyter\n",
        "!python -m ipykernel install --name \"py38\" --user\n",
        "!pip install click -q\n",
        "!pip install numpy -q\n",
        "!pip install pillow -q\n",
        "!pip install torch -q\n",
        "!pip install scipy -q\n",
        "!pip install Ninja -q\n",
        "!pip install imageio -q\n",
        "!pip install imageio-ffmpeg -q\n",
        "!pip install youtube-dl -q\n",
        "clear_output()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select model \n",
        "#@markdown (replay this when you change selection)\n",
        "modellink = 'test'\n",
        "model = \"scifi city - 256 - step 210\" #@param [\"mechanical devices from the future - 256 - step 29\", \"flowers - 256 - step 69\", \"alien sunglases - 256 - step 38\", \"forest daemons - 256 - step 18\", \"scifi city - 256 - step 210\", \"scifi spaceship - 256 - step 162\", \"yellow alien - 512 - step 236\"]\n",
        "if model == 'mechanical devices from the future - 256 - step 29':\n",
        "   modellink = 'https://www.dropbox.com/s/v2oie53cz62ozvu/network-snapshot-000029.pkl?dl=1'\n",
        "if model == 'flowers - 256 - step 69':\n",
        "   modellink = 'https://www.dropbox.com/s/o33lhgnk91hstvx/network-snapshot-000069.pkl?dl=1'\n",
        "if model == 'alien sunglases - 256 - step 38':\n",
        "   modellink = 'https://www.dropbox.com/s/vhwghutjz6xccf9/network-snapshot-000074.pkl?dl=1'\n",
        "if model == 'forest daemons - 256 - step 18':\n",
        "   modellink = 'https://www.dropbox.com/s/26muctr2eq4br6l/network-snapshot-000018.pkl?dl=1'\n",
        "if model == 'scifi city - 256 - step 210':\n",
        "   modellink = 'https://www.dropbox.com/s/1kfsmlct4mriphc/network-snapshot-000210.pkl?dl=1'\n",
        "if model == 'scifi spaceship - 256 - step 162':\n",
        "   modellink = 'https://www.dropbox.com/s/02br3mjkma1hubc/network-snapshot-000162.pkl?dl=1'\n",
        "if model == 'yellow alien - 512 - step 236':\n",
        "   modellink = 'https://www.dropbox.com/s/yzraojzmg2kybjx/network-snapshot-000236.pkl?dl=1'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LNieeZHBub3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkBzNIQ9QsFB",
        "cellView": "form"
      },
      "source": [
        "#@title Generate an image\n",
        "\n",
        "seed = 1053 #@param {type:\"slider\", min:0, max:9999, step:1}\n",
        "\n",
        "# Generate an image using pre-trained model \n",
        "!python gen_images.py --outdir=out --trunc=1 \\\n",
        " --seeds=$seed --network=$modellink\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "img = Image.open('/content/stylegan3/out/seed%04d.png' % seed);\n",
        "plt.imshow(img);\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "8JGiupAAvdqF"
      },
      "source": [
        "#@title Generate an interpolation video\n",
        "%cd /content/stylegan3\n",
        "\n",
        "#@markdown Select Seeds (keyframes):\n",
        "start_seed = 42 #@param {type:\"number\"}\n",
        "stop_seed = 46 #@param {type:\"number\"}\n",
        "#@markdown you like to generate a video grid?\n",
        "n_cols =  1#@param {type:\"number\"}\n",
        "n_rows = 1 #@param {type:\"number\"}\n",
        "\n",
        "# #@markdown How many key frames to have?\n",
        "# num_keyframes = 3 #@param {type:\"number\"}\n",
        "num_keyframes = 3\n",
        "\n",
        "#@markdown How many frames for interpolation between each seed?\n",
        "w_frames = 100 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Total length in frames is `num_keyframes`*`w_frames`\n",
        "\n",
        "assert stop_seed > start_seed, 'Stop_seed should be larger then start_seed'\n",
        "\n",
        "if model == \"stylegan2-cosplay-faces-512x512-px\":\n",
        "    baselink = 'https://l4rz.net/'\n",
        "    model = 'cosplayface-snapshot-004000-18160-FID367.pkl'\n",
        "\n",
        "if model == 'sneakers':\n",
        "    if 'sneaksnap.pkl' not in os.listdir('/content/stylegan3'):\n",
        "        !gdown --id 1ReK9P4dkkClvpswdSuew35xCx2xjVsQa\n",
        "    baselink = '/content/stylegan3/'\n",
        "    model = 'sneaksnap.pkl'\n",
        "\n",
        "# Render a  grid of interpolations for seeds N through K.\n",
        "!python gen_video.py --output=lerp.mp4 --trunc=1 --seeds=$start_seed-$stop_seed --grid={n_rows}x{n_cols} \\\n",
        "    --network=$modellink \\\n",
        "    --w-frames=$w_frames\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('lerp.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "<i>right click and \"save video\" for download</i>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Generate ðŸŽµ music video\n",
        "#@markdown ##**Choose your settings**\n",
        "from IPython.display import clear_output\n",
        "%cd /content/stylegan3\n",
        "\n",
        "import requests\n",
        "import pickle\n",
        "import torch \n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa\n",
        "from scipy.io import wavfile\n",
        "\n",
        "import time\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import ImageOps\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "def fetch_model(url_or_path):\n",
        "    basename = os.path.basename(url_or_path)\n",
        "    if os.path.exists(basename):\n",
        "        return basename\n",
        "    else:\n",
        "        !wget -c '{url_or_path}'\n",
        "        return basename\n",
        "\n",
        "baselink ='https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/'\n",
        "model = \"stylegan3-r-ffhq-1024x1024.pkl\" #@param [\"sneakers\", \"stylegan2-cosplay-faces-512x512-px\", \"stylegan3-r-afhqv2-512x512.pkl\", \"stylegan3-r-ffhq-1024x1024.pkl\", \"stylegan3-r-ffhqu-1024x1024.pkl\",\"stylegan3-r-ffhqu-256x256.pkl\",\"stylegan3-r-metfaces-1024x1024.pkl\",\"stylegan3-r-metfacesu-1024x1024.pkl\",\"stylegan3-t-afhqv2-512x512.pkl\",\"stylegan3-t-ffhq-1024x1024.pkl\",\"stylegan3-t-ffhqu-1024x1024.pkl\",\"stylegan3-t-ffhqu-256x256.pkl\",\"stylegan3-t-metfaces-1024x1024.pkl\",\"stylegan3-t-metfacesu-1024x1024.pkl\"]\n",
        "\n",
        "if model == \"stylegan2-cosplay-faces-512x512-px\":\n",
        "    baselink = 'https://l4rz.net/'\n",
        "    model = 'cosplayface-snapshot-004000-18160-FID367.pkl'\n",
        "\n",
        "network_url = baselink + model\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "if model == 'sneakers':\n",
        "    if 'sneaksnap.pkl' not in os.listdir('/content/stylegan3'):\n",
        "        !gdown --id 1ReK9P4dkkClvpswdSuew35xCx2xjVsQa\n",
        "    network_url = '/content/stylegan3/sneaksnap.pkl'\n",
        "\n",
        "with open(fetch_model(network_url), 'rb') as fp:\n",
        "  G = pickle.load(fp)['G_ema'].to(device)\n",
        "\n",
        "seed =  42#@param {type:\"number\"}\n",
        "\n",
        "#@markdown How variable should the video be? (lower values - less variable)\n",
        "#if you are reading that - you are smart enough to map frequencies to psi as well\n",
        "truncation_psi = 0.5 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown How strongly should the image change?\n",
        "effect_strength =  1#@param {type:\"number\"}\n",
        "\n",
        "zs = torch.randn([10000, G.mapping.z_dim], device=device)\n",
        "w_stds = G.mapping(zs, None).std(0)\n",
        "\n",
        "#@markdown Link to MP3 audio file (you can also extact music from a Youtube link)\n",
        "audio_link = 'https://cdn.pixabay.com/download/audio/2021/03/26/audio_dd57ac8732.mp3?filename=east-2-west-3513.mp3' #@param {type:\"string\"}\n",
        "if 'youtu.be' not in audio_link:\n",
        "    !wget {audio_link} -O audio.mp3\n",
        "else:\n",
        "    !youtube-dl --extract-audio --audio-format mp3 https://youtu.be/0OkiUUU3Odw -o music_temp.mp3\n",
        "    !ffmpeg -i music_temp.mp3 -af silenceremove=1:0:-50dB audio.mp3\n",
        "\n",
        "#@markdown Cut audio to N seconds\n",
        "cut_start =  15#@param {type:\"number\"}\n",
        "cut_end =  30#@param {type:\"number\"}\n",
        "\n",
        "cut_len = cut_end-cut_start \n",
        "\n",
        "#@markdown How many frames to use for interpolation?\n",
        "interp_frames =  5#@param {type:\"number\"}\n",
        "\n",
        "#@markdown Which frequencies to use?\n",
        "freqs = 'all' #@param ['low', 'high', 'all']\n",
        "\n",
        "arr, fr = librosa.load('audio.mp3')\n",
        "arr = arr[int(fr*cut_start):int(fr*cut_end)]\n",
        "\n",
        "wavfile.write('audio.wav', fr, arr)\n",
        "\n",
        "# stft = torch.stft(torch.tensor(arr), \n",
        "#            G.mapping.z_dim*2-1,\n",
        "#            hop_length=G.mapping.z_dim//4,  \n",
        "#            center=False, \n",
        "#            pad_mode='reflect', \n",
        "#            normalized=True, \n",
        "#            onesided=True, \n",
        "#            return_complex=True)\n",
        "\n",
        "stft=librosa.feature.melspectrogram(y=arr, \n",
        "                               sr=fr,\n",
        "                               n_fft=2048,\n",
        "                               hop_length=G.mapping.z_dim*4,\n",
        "                               n_mels=G.mapping.z_dim)\n",
        "\n",
        "stft = torch.log(torch.tensor(stft).abs())\n",
        "\n",
        "if freqs == 'low':\n",
        "    stft[stft.size(0)//2:, :] *= 10\n",
        "\n",
        "if freqs == 'high':\n",
        "    stft[:stft.size(0)//2, :] *= 10\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#FRAMES\n",
        "import time\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "zq = []\n",
        "with torch.no_grad():\n",
        "    timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "    # rand_z = torch.randn(stft.size(-1), G.mapping.z_dim).to(device)\n",
        "    # q = (G.mapping(rand_z, None, truncation_psi=truncation_psi))\n",
        "\n",
        "    for i in range(stft.size(-1)):\n",
        "        frame = stft[:,i].T.to(device)\n",
        "        z = torch.mean(G.mapping(frame.unsqueeze(0), None, truncation_psi=truncation_psi), dim=0)\n",
        "        zq.append(z.unsqueeze(0)*effect_strength)\n",
        "\n",
        "    count = 0\n",
        "    for k in tqdm(range(len(zq)-1)):\n",
        "        i_val = torch.linspace(0,1,interp_frames).to(device)\n",
        "        for interpolation in tqdm(i_val, leave=False):\n",
        "            interp = torch.lerp(zq[k], zq[k+1], interpolation)\n",
        "            images = G.synthesis(interp)\n",
        "            images = ((images + 1)/2).clamp(0,1)\n",
        "            pil_image = TF.to_pil_image(images[0].cpu())\n",
        "            if model == 'sneakers':\n",
        "                pil_image = ImageOps.invert(pil_image)\n",
        "            os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "            pil_image.save(f'samples/{timestring}/{count:04}.png')\n",
        "            count+=1\n",
        "\n",
        "\n",
        "#VIDEO\n",
        "from IPython import display\n",
        "from base64 import b64encode\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "fps = count/cut_len\n",
        "\n",
        "frames = []\n",
        "# tqdm.write('Generating video...')\n",
        "for i in sorted(os.listdir(f'samples/{timestring}')): #\n",
        "    frames.append(Image.open(f\"samples/{timestring}/{i}\"))\n",
        "\n",
        "from subprocess import Popen, PIPE\n",
        "p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', 'video.mp4'], stdin=PIPE)\n",
        "for im in tqdm(frames):\n",
        "    im.save(p.stdin, 'PNG')\n",
        "p.stdin.close()\n",
        "p.wait()\n",
        "\n",
        "!ffmpeg -y -i video.mp4 -i audio.wav -map 0 -map 1:a -c:v copy -shortest video_audio.mp4\n",
        "\n",
        "clear_output()\n",
        "# mp4 = open('video.mp4','rb').read()\n",
        "mp4 = open('video_audio.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "display.HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)\n",
        "\n",
        "#@markdown P.S.: If it crushed - look for `video-audio.mp4` in `stylegan3` folder"
      ],
      "metadata": {
        "id": "8FCaEVuSXlTU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}